{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get NHS data\n",
    "\n",
    "import zipfile\n",
    "import urllib2\n",
    "import os\n",
    "\n",
    "source_url = 'ftp://ftp.nhtsa.dot.gov/GES/GES12/GES12_Flatfile.zip'\n",
    "zip_name = 'GES12_Flatfile.zip'\n",
    "cwd = os.getcwd()\n",
    "dir_path = os.path.join(cwd, 'GES2012')\n",
    "zip_path = os.path.join(dir_path, zip_name)\n",
    "\n",
    "# We'll make a directory to play around with\n",
    "# Then when done playing you can just delete the directory\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    \n",
    "# Download the file from GES website if you haven't already\n",
    "if not os.path.exists(zip_path):\n",
    "    response = urllib2.urlopen(source_url)\n",
    "    with open(zip_path, 'wb') as fh:\n",
    "        x = response.read()\n",
    "        fh.write(x)\n",
    "        \n",
    "# Extract all the files from that zipfile\n",
    "with zipfile.ZipFile(os.path.join(dir_path, zip_name), 'r') as z:\n",
    "    z.extractall(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012GESFlatFileTXT.sas',\n",
       " 'ACCIDENT.TXT',\n",
       " 'CEVENT.TXT',\n",
       " 'DAMAGE.TXT',\n",
       " 'DISTRACT.TXT',\n",
       " 'DRIMPAIR.TXT',\n",
       " 'FACTOR.TXT',\n",
       " 'GES12_Flatfile.zip',\n",
       " 'MANEUVER.TXT',\n",
       " 'NMCRASH.TXT',\n",
       " 'NMIMPAIR.TXT',\n",
       " 'NMPRIOR.TXT',\n",
       " 'PARKWORK.TXT',\n",
       " 'PERSON.TXT',\n",
       " 'SAFETYEQ.TXT',\n",
       " 'VEHICLE.TXT',\n",
       " 'VEVENT.TXT',\n",
       " 'VIOLATN.TXT',\n",
       " 'VISION.TXT',\n",
       " 'VSOE.TXT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see what we just unzipped\n",
    "os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGE',\n",
       " 'AGE_IM',\n",
       " 'AIR_BAG',\n",
       " 'ALC_RES',\n",
       " 'ALC_STATUS',\n",
       " 'ATST_TYP',\n",
       " 'BODY_TYP',\n",
       " 'CASENUM',\n",
       " 'DRINKING',\n",
       " 'DRUGRES1',\n",
       " 'DRUGRES2',\n",
       " 'DRUGRES3',\n",
       " 'DRUGS',\n",
       " 'DRUGTST1',\n",
       " 'DRUGTST2',\n",
       " 'DRUGTST3',\n",
       " 'DSTATUS',\n",
       " 'EJECTION',\n",
       " 'EJECT_IM',\n",
       " 'EMER_USE',\n",
       " 'FIRE_EXP',\n",
       " 'HARM_EV',\n",
       " 'HOSPITAL',\n",
       " 'HOUR',\n",
       " 'IMPACT1',\n",
       " 'INJSEV_IM',\n",
       " 'INJ_SEV',\n",
       " 'LOCATION',\n",
       " 'MAKE',\n",
       " 'MAN_COLL',\n",
       " 'MINUTE',\n",
       " 'MOD_YEAR',\n",
       " 'MONTH',\n",
       " 'PERALCH_IM',\n",
       " 'PER_NO',\n",
       " 'PER_TYP',\n",
       " 'PJ',\n",
       " 'PSU',\n",
       " 'PSUSTRAT',\n",
       " 'P_SF1',\n",
       " 'P_SF2',\n",
       " 'P_SF3',\n",
       " 'REGION',\n",
       " 'REST_MIS',\n",
       " 'REST_USE',\n",
       " 'ROLLOVER',\n",
       " 'SCH_BUS',\n",
       " 'SEAT_IM',\n",
       " 'SEAT_POS',\n",
       " 'SEX',\n",
       " 'SEX_IM',\n",
       " 'SPEC_USE',\n",
       " 'STRATUM',\n",
       " 'STR_VEH',\n",
       " 'TOW_VEH',\n",
       " 'VEH_NO',\n",
       " 'VE_FORMS',\n",
       " 'WEIGHT']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "cwd = os.getcwd()\n",
    "dir_path = os.path.join(cwd, 'GES2012')\n",
    "input_file_path = os.path.join(dir_path, 'PERSON.TXT')\n",
    "\n",
    "input_data = pd.read_csv(input_file_path, delimiter='\\t')\n",
    "\n",
    "sorted(input_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100840\n",
       "2     20758\n",
       "1     19380\n",
       "3      9738\n",
       "5      1179\n",
       "4      1178\n",
       "6         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up data\n",
    "input_data.INJSEV_IM.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKE 5162\n",
      "BODY_TYP 5162\n",
      "MOD_YEAR 5162\n",
      "TOW_VEH 5162\n",
      "SPEC_USE 5162\n",
      "EMER_USE 5162\n",
      "ROLLOVER 5162\n",
      "IMPACT1 5162\n",
      "FIRE_EXP 5162\n"
     ]
    }
   ],
   "source": [
    "# only four cases where person died before crash, so just ignore.\n",
    "# Some columns have missing values:\n",
    "\n",
    "# Drop odd cases\n",
    "input_data = input_data[input_data.INJSEV_IM != 6]\n",
    "\n",
    "for column_name in input_data.columns:\n",
    "    n_nans = input_data[column_name].isnull().sum()\n",
    "    if n_nans > 0:\n",
    "        print column_name, n_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153073, 58)\n",
      "(147911, 56)\n"
     ]
    }
   ],
   "source": [
    "print input_data.shape\n",
    "data = input_data[~input_data.MAKE.isnull()]\n",
    "discarded = data.pop('INJ_SEV')\n",
    "target = data.pop('INJSEV_IM')\n",
    "print data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One last preprocessing step we'll do it transform the response.\n",
    "# Category 4 is a fatal injury, so we will encode as such\n",
    "\n",
    "target = (target == 4).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: Area under the ROC curve = 0.932776711135\n"
     ]
    }
   ],
   "source": [
    "# Now we model!\n",
    "# We will use ols, Ridge Regression, Lasso Regression,\n",
    "# Gradient Boosting Machine, and a CART\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Train on half of the data while reserving other half for\n",
    "# model comparison\n",
    "xtrain, xtest, ytrain, ytest = sklearn.cross_validation.train_test_split(\n",
    "    data.values, target.values, train_size=0.5)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(xtrain, ytrain)\n",
    "\n",
    "lr_preds = linreg.predict(xtest)\n",
    "lr_perf = roc_auc_score(ytest, lr_preds)\n",
    "print 'OLS: Area under the ROC curve = {}'.format(lr_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: Area under the ROC curve = 0.932786784372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = GridSearchCV(Ridge(),\n",
    "                    {'alpha': np.logspace(-10, 10, 100)})\n",
    "ridge.fit(xtrain, ytrain)\n",
    "ridge_preds = ridge.predict(xtest)\n",
    "ridge_performance = roc_auc_score(ytest, ridge_preds)\n",
    "print 'Ridge: Area under the ROC curve = {}'.format(ridge_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: Area under the ROC curve = (array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), array([-0.01110595,  0.00548702,  0.02903895, ..., -0.00785013,\n",
      "       -0.00217249, -0.00817287]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "lasso = GridSearchCV(Lasso(),\n",
    "                    {'alpha': np.logspace(-10, -8, 5)})\n",
    "lasso.fit(xtrain, ytrain)\n",
    "lasso_preds = lasso.predict(xtest)\n",
    "lasso_performance = (ytest, lasso_preds)\n",
    "print 'Lasso: Area under the ROC curve = {}'.format(lasso_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: Area under the ROC curve =0.973048391666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=500)\n",
    "\n",
    "gbm.fit(xtrain, ytrain)\n",
    "gbm_preds = gbm.predict_proba(xtest)[:, 1]\n",
    "gbm_performance = roc_auc_score(ytest, gbm_preds)\n",
    "\n",
    "print 'GBM: Area under the ROC curve ={}'.format(gbm_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Area under the ROC curve = 0.9119433573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tree = GridSearchCV(DecisionTreeClassifier(),\n",
    "                   {'max_depth': np.arange(3, 10)})\n",
    "tree.fit(xtrain, ytrain)\n",
    "tree_preds = tree.predict_proba(xtest)[:, 1]\n",
    "tree_perf = roc_auc_score(ytest, tree_preds)\n",
    "\n",
    "print \"Decision Tree: Area under the ROC curve = {}\".format(tree_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATUM     0.083548\n",
      "WEIGHT      0.063752\n",
      "DRINKING    0.060818\n",
      "EJECT_IM    0.060524\n",
      "CASENUM     0.050680\n",
      "HARM_EV     0.041842\n",
      "AGE_IM      0.040943\n",
      "IMPACT1     0.039241\n",
      "ALC_RES     0.038808\n",
      "HOSPITAL    0.032949\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See what variables the GBM model thinks are most useful\n",
    "\n",
    "importances = pd.Series(gbm.feature_importances_, index=data.columns)\n",
    "print importances.order(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
